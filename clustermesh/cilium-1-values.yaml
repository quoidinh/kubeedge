debug:
  enabled: true
nodeinit:
  enabled: true
  restartPods: true
# kubeProxyReplacement: partial
hostServices:
  enabled: false
externalIPs:
  enabled: true
nodePort:
  enabled: true
hostPort:
  enabled: true
ipam:
  mode: kubernetes
bpf:
  masquerade: false
hubble:
  enabled: true
  ui:
    enabled: true
  relay:
    enabled: true
# -- Configure certificate generation for Hubble integration.
# If hubble.tls.auto.method=cronJob, these values are used
# for the Kubernetes CronJob which will be scheduled regularly to
# (re)generate any certificates not provided manually.
certgen:
  image:
    # @schema
    # type: [null, string]
    # @schema
    override: ~
    repository: "quay.io/cilium/certgen"
    tag: "v0.2.1"
    digest: "sha256:ab6b1928e9c5f424f6b0f51c68065b9fd85e2f8d3e5f21fbd1a3cb27e6fb9321"
    useDigest: true
    pullPolicy: "Always"
  # -- Seconds after which the completed job pod will be deleted
  ttlSecondsAfterFinished: 1800
  # -- Labels to be added to hubble-certgen pods
  podLabels: {}
  # -- Annotations to be added to the hubble-certgen initial Job and CronJob
  annotations:
    job: {}
    cronJob: {}
  # -- Node tolerations for pod assignment on nodes with taints
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
  tolerations: []
  # -- Additional certgen volumes.
  extraVolumes: []
  # -- Additional certgen volumeMounts.
  extraVolumeMounts: []
  # -- Affinity for certgen
  affinity: {}
# -- Configure L2 announcements
# l2announcements:
#   # -- Enable L2 announcements
#   enabled: true
  # -- If a lease is not renewed for X duration, the current leader is considered dead, a new leader is picked
  # leaseDuration: 15s
  # -- The interval at which the leader will renew the lease
  # leaseRenewDeadline: 5s
  # -- The timeout between retries if renewal fails
  # leaseRetryPeriod: 2s
# -- Configure L2 pod announcements
# l2podAnnouncements:
#   # -- Enable L2 pod announcements
#   enabled: true
#   # -- Interface used for sending Gratuitous ARP pod announcements
#   interface: "eth0"
# # -- Configure BGP
# bgp:
#   # -- Enable BGP support inside Cilium; embeds a new ConfigMap for BGP inside
#   # cilium-agent and cilium-operator
#   enabled: true
#   announce:
#     # -- Enable allocation and announcement of service LoadBalancer IPs
#     loadbalancerIP: false
#     # -- Enable announcement of node pod CIDR
#     podCIDR: false
# -- This feature set enables virtual BGP routers to be created via
# CiliumBGPPeeringPolicy CRDs.
bgpControlPlane:
  # -- Enables the BGP control plane.
  enabled: true
  # -- SecretsNamespace is the namespace which BGP support will retrieve secrets from.
  secretsNamespace:
    # -- Create secrets namespace for BGP secrets.
    create: false
    # -- The name of the secret namespace to which Cilium agents are given read access
    name: kube-system
etcd:
  # -- Enable etcd mode for the agent.
  enabled: true
  # -- List of etcd endpoints
  endpoints:
    - https://172.16.0.149:2379
    - https://172.16.0.66:2379
    # - https://172.16.0.59:2379
    # - https://172.16.0.81:2379
    # - https://172.16.0.67:2379
  # -- Enable use of TLS/SSL for connectivity to etcd.
  ssl: true
cluster:
  id: 1
  name: cluster1
clustermesh:
  useAPIServer: true
  config:
    enabled: true
    clusters:
    - name: kind-cluster1
      port: 2379
      ips:
      - 172.16.0.149
      tls:
        # tls.crt from clustermesh-apiserver-remote-cert secret in Cluster 1
        # tls.key from clustermesh-apiserver-remote-cert secret in Cluster 1
        # cert: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURpakNDQVhLZ0F3SUJBZ0lVSkE1MmNhWHZKdmxzdVRpWXhCckQ3aGtDTzhFd0RRWUpLb1pJaHZjTkFRRU4KQlFBd1JURUxNQWtHQTFVRUJoTUNWVk14RXpBUkJnTlZCQWdNQ2xkaGMyaHBibWQwYjI0eEVEQU9CZ05WQkFjTQpCMU5sWVhSMGJHVXhEekFOQmdOVkJBTU1Ca05wYkdsMWJUQWVGdzB5TkRBNU1ESXhOREEyTURCYUZ3MHlOekE1Ck1ESXhOREEyTURCYU1CRXhEekFOQmdOVkJBTVRCbkpsYlc5MFpUQlpNQk1HQnlxR1NNNDlBZ0VHQ0NxR1NNNDkKQXdFSEEwSUFCQ1k0eFBHU3JvWmF2b2FCbHpyZ0l3dXR2eWVEVUdLT1lSZDFCY0VOZzljQWJYcGpYM0RyS0ozYgpLRjBZbXVIWlByK2pETkZWakdJWVVmWFBROWJIT3FlamNUQnZNQTRHQTFVZER3RUIvd1FFQXdJRm9EQWRCZ05WCkhTVUVGakFVQmdnckJnRUZCUWNEQVFZSUt3WUJCUVVIQXdJd0RBWURWUjBUQVFIL0JBSXdBREFkQmdOVkhRNEUKRmdRVXNwTDAydzBGNzZzZDVhTE1DenF5UXhRUXFud3dFUVlEVlIwUkJBb3dDSUlHY21WdGIzUmxNQTBHQ1NxRwpTSWIzRFFFQkRRVUFBNElDQVFDN0t4djBHRjAyRlFvbS9zUjU1dytjcUJvcUxON1FJaEx6eGVYRlNHTXhJa0VUClUwTklHQThtcjkvUS9obENENFE2eXhlTTRzRkhab0tnOGgydXdsU0tRYkNmbGM0QVhkWmovU1FDQTVzZ1NIdFcKa1BtcGhQME5jTGNObFM3UmFic0RtLzk5NXpoMjRFWDVFdmZ3WE15aDRGR0lqSW1JUE0vbDhuUXZjN2pNL0JUeQpyZzk0eUxtK3hkQ0RFblduZkMzSUFkU0pmcXVqTVNxRm9UMGk1UXRwSit3dEltTnFVZ3F1MzNWb0lhN0NDdnpjCnA5M0x5OVJIUU1kblpNT2JjWlpGZlZyaHdVRVJQdklJcEpGa0ZXTFVlbjY5NDl4WGQ1N25wai9WQkEyd1U0L28KRW81SCtGV0VlZmpieC9tU211WXFnR0JsVUJGY0YrNllldjM0NHdrQkQwZU83M1JpbG5HNVNPYjUxdzU0WWtaZwpuTG1CS0NDQ0ViTXRoSms5eFhIUTZyMXBLb1pIcURQZERqL3dqMUwrQ3NCTU1FWkVDdTR5dWE0bjJMZGgvdU4yCkNJU2txTWY1enVjQzJUZzlNVlNRWk1Xc0hJTktMSGc5MERyWVhqcEJuUVlzWGNQV2NFaHhIQkdmekVMbXdnQkgKUTF0bjQ4djdiQk4vdjZVNzlRUDBHRXdJUkNoRzBFb01oWTAzazVWYjBOWFIwSHg4ZlhqUFhSaEV2eGt0MElYNwpzelM1L1dsMlV6QWNQVFhtejZCUVZSS1FXRjNpanRnbEt2TklqWWFnMENOR1ZCZ0JLVHJzNTRKbW1qT3VySDZWCnhFbFc5cFNBY0p2TkVpM3A2NDJtbFlpR0phaVEzT3BtUlZ6dFVRSTkxaXNDdTgrRlpzVVJVWDU5d2VETSt3PT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
        # key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSURQOEFlVm1iQ3dJU0tONzR6L3V1STZFbXMweUg1RjBSblRicVEwWk1xU2lvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFSmpqRThaS3VobHEraG9HWE91QWpDNjIvSjROUVlvNWhGM1VGd1EyRDF3QnRlbU5mY09zbwpuZHNvWFJpYTRkayt2Nk1NMFZXTVloaFI5YzlEMXNjNnB3PT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
    - name: kind-cluster2
      port: 2379
      ips:
      - 172.16.0.66
      tls:
        #kubectl get secret clustermesh-apiserver-remote-cert -n kube-system -o yaml
        # tls.crt from clustermesh-apiserver-remote-cert secret in Cluster 1
        # tls.key from clustermesh-apiserver-remote-cert secret in Cluster 1
    #     cert: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJtekNDQVVLZ0F3SUJBZ0lVR2Y1N0pEem9TZE9STGNTREdpSS9DNEdQLzNZd0NnWUlLb1pJemowRUF3SXcKRkRFU01CQUdBMVVFQXhNSlEybHNhWFZ0SUVOQk1CNFhEVEkwTURrd01qRXlOVGt3TUZvWERUSTNNRGt3TWpFeQpOVGt3TUZvd0VURVBNQTBHQTFVRUF4TUdjbVZ0YjNSbE1Ga3dFd1lIS29aSXpqMENBUVlJS29aSXpqMERBUWNEClFnQUUvSlZReWEwMnFrWm9Mby9BZDlGV0ZmUE5Oc3FUM0JQVGdGSnJyWXk4TE83WUwwVXZLdlEzVUEvV0NGWDIKR01LQ29rVDNWL2VDeTBiN09vM3lUSlF3a2FOMU1ITXdEZ1lEVlIwUEFRSC9CQVFEQWdXZ01CTUdBMVVkSlFRTQpNQW9HQ0NzR0FRVUZCd01DTUF3R0ExVWRFd0VCL3dRQ01BQXdIUVlEVlIwT0JCWUVGTDYySksrYnh1TTNlaVFHCnprZkljTkJVYzlkT01COEdBMVVkSXdRWU1CYUFGTXhMUlk5aWdSSEtlUEc1K2J4M1BLSUl4bVdnTUFvR0NDcUcKU000OUJBTUNBMGNBTUVRQ0lESFdwNXFtUVk1TDJwWXdkbWR2VG9JOW1hNjV1Mk1ESjdJRy9hbWVrRmhSQWlCegoyS2dLWWwrWjZUNWVML1AvdmkyT2xnTkJPSXhwdkpZdVppa0JUemlHVWc9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    #     key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUowWGlqK2ZGOENidmNMYmhWdGJoK1VuUE1HZ0NJTkNJYVFOekMxMlEwZnBvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFL0pWUXlhMDJxa1pvTG8vQWQ5RldGZlBOTnNxVDNCUFRnRkpycll5OExPN1lMMFV2S3ZRMwpVQS9XQ0ZYMkdNS0Nva1QzVi9lQ3kwYjdPbzN5VEpRd2tRPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
    # - name: kind-cluster3
    #   port: 2379
    #   ips:
    #   - 172.16.0.59
    # - name: kind-cluster4
    #   port: 2379
    #   ips:
    #   - 172.16.0.81
    # - name: kind-cluster5
    #   port: 2379
    #   ips:
    #   - 172.16.0.67
  apiserver:
    tls:
      auto:
        enabled: false
    service:
      type: NodePort
      loadBalancerIP: 172.16.0.149 
       
    # -- TCP port for the clustermesh-apiserver health API.
    healthPort: 9880
    etcd:
      # The etcd binary is included in the clustermesh API server image, so the same image from above is reused.
      # Independent override isn't supported, because clustermesh-apiserver is tested against the etcd version it is
      # built with.

      # -- Specifies the resources for etcd container in the apiserver
      resources: {}
      # requests:
      #   cpu: 200m
      #   memory: 256Mi
      # limits:
      #   cpu: 1000m
      #   memory: 256Mi

      # -- Security context to be added to clustermesh-apiserver etcd containers
      securityContext: {}
      # -- lifecycle setting for the etcd container
      lifecycle: {}
      init:
        # -- Specifies the resources for etcd init container in the apiserver
        resources: {}
        requests:
          cpu: 100m
          memory: 100Mi
        limits:
          cpu: 100m
          memory: 100Mi

        # -- Additional arguments to `clustermesh-apiserver etcdinit`.
        extraArgs: []
        # -- Additional environment variables to `clustermesh-apiserver etcdinit`.
        extraEnv: []
    kvstoremesh:
      # -- Enable KVStoreMesh. KVStoreMesh caches the information retrieved
      # from the remote clusters in the local etcd instance.
      enabled: true
      # -- Additional KVStoreMesh arguments.
      extraArgs: []
      # -- Additional KVStoreMesh environment variables.
      extraEnv: []
      # -- Resource requests and limits for the KVStoreMesh container
      resources: {}
      requests:
        cpu: 100m
        memory: 64Mi
      limits:
        cpu: 1000m
        memory: 1024M

      # -- Additional KVStoreMesh volumeMounts.
      extraVolumeMounts: []
      # -- KVStoreMesh Security context
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          drop:
            - ALL
      # -- lifecycle setting for the KVStoreMesh container
      lifecycle: {}
  # apiserver:
  #   tls:
  #     auto:
  #       method: cronJob
  #     ca:
  #       # ca.crt from the cilium-ca secret in Cluster 1 (important - not Cluster 2)
  #       cert: "<base64-encoded-cert>"
  #       # ca.key from the cilium-ca secret in Cluster 1 (important - not Cluster 2)
  #       key: "<base64-encoded-key>"
  #   service:
  #     type: LoadBalancer