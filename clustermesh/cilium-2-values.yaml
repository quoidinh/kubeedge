debug:
  enabled: true
# nodeinit:
#   enabled: true
#   restartPods: true
nodeinit:
  enabled: true
  reconfigureKubelet: true
  removeCbrBridge: true
  restartPods: true
# kubeProxyReplacement: partial
hostServices:
  enabled: false
externalIPs:
  enabled: true
nodePort:
  enabled: true
hostPort:
  enabled: true
ipam:
  mode: kubernetes
bpf:
  masquerade: false
hubble:
  enabled: true
  ui:
    enabled: true
  relay:
    enabled: true
# -- Configure certificate generation for Hubble integration.
# If hubble.tls.auto.method=cronJob, these values are used
# for the Kubernetes CronJob which will be scheduled regularly to
# (re)generate any certificates not provided manually.
certgen:
  image:
    # @schema
    # type: [null, string]
    # @schema
    override: ~
    repository: "quay.io/cilium/certgen"
    tag: "v0.2.1"
    digest: "sha256:ab6b1928e9c5f424f6b0f51c68065b9fd85e2f8d3e5f21fbd1a3cb27e6fb9321"
    useDigest: true
    pullPolicy: "Always"
  # -- Seconds after which the completed job pod will be deleted
  ttlSecondsAfterFinished: 1800
  # -- Labels to be added to hubble-certgen pods
  podLabels: {}
  # -- Annotations to be added to the hubble-certgen initial Job and CronJob
  annotations:
    job: {}
    cronJob: {}
  # -- Node tolerations for pod assignment on nodes with taints
  # ref: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
  tolerations: []
  # -- Additional certgen volumes.
  extraVolumes: []
  # -- Additional certgen volumeMounts.
  extraVolumeMounts: []
  # -- Affinity for certgen
  affinity: {}
# -- Configure L2 announcements
# l2announcements:
#   # -- Enable L2 announcements
#   enabled: true
  # -- If a lease is not renewed for X duration, the current leader is considered dead, a new leader is picked
  # leaseDuration: 15s
  # -- The interval at which the leader will renew the lease
  # leaseRenewDeadline: 5s
  # -- The timeout between retries if renewal fails
  # leaseRetryPeriod: 2s
# -- Configure L2 pod announcements
# l2podAnnouncements:
#   # -- Enable L2 pod announcements
#   enabled: true
#   # -- Interface used for sending Gratuitous ARP pod announcements
#   interface: "eth0"
# # -- Configure BGP
# bgp:
#   # -- Enable BGP support inside Cilium; embeds a new ConfigMap for BGP inside
#   # cilium-agent and cilium-operator
#   enabled: true
#   announce:
#     # -- Enable allocation and announcement of service LoadBalancer IPs
#     loadbalancerIP: false
#     # -- Enable announcement of node pod CIDR
#     podCIDR: false
# -- This feature set enables virtual BGP routers to be created via
# CiliumBGPPeeringPolicy CRDs.
# bgpControlPlane:
#   # -- Enables the BGP control plane.
#   enabled: true
#   # -- SecretsNamespace is the namespace which BGP support will retrieve secrets from.
#   secretsNamespace:
#     # -- Create secrets namespace for BGP secrets.
#     create: false
#     # -- The name of the secret namespace to which Cilium agents are given read access
#     name: kube-system
etcd:
  # -- Enable etcd mode for the agent.
  enabled: true
  # -- List of etcd endpoints
  endpoints:
    - https://172.16.0.149:2379
    - https://172.16.0.66:2379
    - https://172.16.0.157:2379
    - https://172.16.0.234:2379
#   # -- Enable use of TLS/SSL for connectivity to etcd.
  ssl: true
cluster:
  id: 2
  name: cluster2
clustermesh:
  useAPIServer: true
  config:
    enabled: true
    clusters:
    - name: kind-cluster1
      port: 2379
      ips:
      - 172.16.0.149
    - name: kind-cluster2
      port: 2379
      ips:
      - 172.16.0.66
      # tls:
        #kubectl get secret clustermesh-apiserver-remote-cert -n kube-system -o yaml
        # tls.crt from clustermesh-apiserver-remote-cert secret in Cluster 1
        # tls.key from clustermesh-apiserver-remote-cert secret in Cluster 1
    #     cert: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJtekNDQVVLZ0F3SUJBZ0lVR2Y1N0pEem9TZE9STGNTREdpSS9DNEdQLzNZd0NnWUlLb1pJemowRUF3SXcKRkRFU01CQUdBMVVFQXhNSlEybHNhWFZ0SUVOQk1CNFhEVEkwTURrd01qRXlOVGt3TUZvWERUSTNNRGt3TWpFeQpOVGt3TUZvd0VURVBNQTBHQTFVRUF4TUdjbVZ0YjNSbE1Ga3dFd1lIS29aSXpqMENBUVlJS29aSXpqMERBUWNEClFnQUUvSlZReWEwMnFrWm9Mby9BZDlGV0ZmUE5Oc3FUM0JQVGdGSnJyWXk4TE83WUwwVXZLdlEzVUEvV0NGWDIKR01LQ29rVDNWL2VDeTBiN09vM3lUSlF3a2FOMU1ITXdEZ1lEVlIwUEFRSC9CQVFEQWdXZ01CTUdBMVVkSlFRTQpNQW9HQ0NzR0FRVUZCd01DTUF3R0ExVWRFd0VCL3dRQ01BQXdIUVlEVlIwT0JCWUVGTDYySksrYnh1TTNlaVFHCnprZkljTkJVYzlkT01COEdBMVVkSXdRWU1CYUFGTXhMUlk5aWdSSEtlUEc1K2J4M1BLSUl4bVdnTUFvR0NDcUcKU000OUJBTUNBMGNBTUVRQ0lESFdwNXFtUVk1TDJwWXdkbWR2VG9JOW1hNjV1Mk1ESjdJRy9hbWVrRmhSQWlCegoyS2dLWWwrWjZUNWVML1AvdmkyT2xnTkJPSXhwdkpZdVppa0JUemlHVWc9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    #     key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUowWGlqK2ZGOENidmNMYmhWdGJoK1VuUE1HZ0NJTkNJYVFOekMxMlEwZnBvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFL0pWUXlhMDJxa1pvTG8vQWQ5RldGZlBOTnNxVDNCUFRnRkpycll5OExPN1lMMFV2S3ZRMwpVQS9XQ0ZYMkdNS0Nva1QzVi9lQ3kwYjdPbzN5VEpRd2tRPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
    - name: kind-cluster3
      port: 2379
      ips:
      - 172.16.0.157
    - name: kind-cluster4
      port: 2379
      ips:
      - 172.16.0.234
    # - name: kind-cluster5
    #   port: 2379
    #   ips:
    #   - 172.16.0.67
  # apiserver:
  #   tls:
  #     auto:
  #       enabled: false
  #   service:
  #     type: NodePort
  #     # loadBalancerIP: 172.16.0.149 
       
  #   # -- TCP port for the clustermesh-apiserver health API.
  #   healthPort: 9880
  #   etcd:
  #     # The etcd binary is included in the clustermesh API server image, so the same image from above is reused.
  #     # Independent override isn't supported, because clustermesh-apiserver is tested against the etcd version it is
  #     # built with.

  #     # -- Specifies the resources for etcd container in the apiserver
  #     resources: {}
  #     # requests:
  #     #   cpu: 200m
  #     #   memory: 256Mi
  #     # limits:
  #     #   cpu: 1000m
  #     #   memory: 256Mi

  #     # -- Security context to be added to clustermesh-apiserver etcd containers
  #     securityContext: {}
  #     # -- lifecycle setting for the etcd container
  #     lifecycle: {}
  #     init:
  #       # -- Specifies the resources for etcd init container in the apiserver
  #       resources: {}
  #       requests:
  #         cpu: 100m
  #         memory: 100Mi
  #       limits:
  #         cpu: 100m
  #         memory: 100Mi

  #       # -- Additional arguments to `clustermesh-apiserver etcdinit`.
  #       extraArgs: []
  #       # -- Additional environment variables to `clustermesh-apiserver etcdinit`.
  #       extraEnv: []
  #   kvstoremesh:
  #     # -- Enable KVStoreMesh. KVStoreMesh caches the information retrieved
  #     # from the remote clusters in the local etcd instance.
  #     enabled: true
  #     # -- Additional KVStoreMesh arguments.
  #     extraArgs: []
  #     # -- Additional KVStoreMesh environment variables.
  #     extraEnv: []
  #     # -- Resource requests and limits for the KVStoreMesh container
  #     resources: {}
  #     requests:
  #       cpu: 100m
  #       memory: 64Mi
  #     limits:
  #       cpu: 1000m
  #       memory: 1024M

  #     # -- Additional KVStoreMesh volumeMounts.
  #     extraVolumeMounts: []
  #     # -- KVStoreMesh Security context
  #     securityContext:
  #       allowPrivilegeEscalation: true
  #       capabilities:
  #         drop:
  #           - ALL
  #     # -- lifecycle setting for the KVStoreMesh container
  #     lifecycle: {}
  # apiserver:
  #   tls:
  #     auto:
  #       method: cronJob
  #     ca:
  #       # ca.crt from the cilium-ca secret in Cluster 1 (important - not Cluster 2)
  #       cert: "<base64-encoded-cert>"
  #       # ca.key from the cilium-ca secret in Cluster 1 (important - not Cluster 2)
  #       key: "<base64-encoded-key>"
  #   service:
  #     type: LoadBalancer

    apiserver:
      service:
        type: NodePort
      # service:
      #   type: LoadBalancer
        annotations:
          cloud.google.com/load-balancer-type: Internal
          external-dns.alpha.kubernetes.io/hostname: clustermesh-apiserver.${cluster_type}.stacksec.local
      # -- TCP port for the clustermesh-apiserver health API.
      healthPort: 9880
      etcd:
        # The etcd binary is included in the clustermesh API server image, so the same image from above is reused.
        # Independent override isn't supported, because clustermesh-apiserver is tested against the etcd version it is
        # built with.

        # -- Specifies the resources for etcd container in the apiserver
        resources: {}
        # requests:
        #   cpu: 200m
        #   memory: 256Mi
        # limits:
        #   cpu: 1000m
        #   memory: 256Mi

        # -- Security context to be added to clustermesh-apiserver etcd containers
        securityContext: {}
        # -- lifecycle setting for the etcd container
        lifecycle: {}
        init:
          # -- Specifies the resources for etcd init container in the apiserver
          resources: {}
          requests:
            cpu: 100m
            memory: 100Mi
          limits:
            cpu: 100m
            memory: 100Mi

          # -- Additional arguments to `clustermesh-apiserver etcdinit`.
          extraArgs: []
          # -- Additional environment variables to `clustermesh-apiserver etcdinit`.
          extraEnv: []
      kvstoremesh:
        # -- Enable KVStoreMesh. KVStoreMesh caches the information retrieved
        # from the remote clusters in the local etcd instance.
        enabled: true
        # -- Additional KVStoreMesh arguments.
        extraArgs: []
        # -- Additional KVStoreMesh environment variables.
        extraEnv: []
        # -- Resource requests and limits for the KVStoreMesh container
        resources: {}
        requests:
          cpu: 100m
          memory: 64Mi
        limits:
          cpu: 1000m
          memory: 1024M

        # -- Additional KVStoreMesh volumeMounts.
        extraVolumeMounts: []
        # -- KVStoreMesh Security context
        securityContext:
          allowPrivilegeEscalation: true
          capabilities:
            drop:
              - ALL
        # -- lifecycle setting for the KVStoreMesh container
        lifecycle: {}
      tls:
        auto:
          enabled: true
          method: certmanager
          certManagerIssuerRef:
            group: cert-manager.io
            kind: ClusterIssuer
            name: stacksec-ca
        server:
          extraDnsNames: 
            - "clustermesh-apiserver.${cluster_type}.stacksec.local"
            - "clustermesh-apiserver.kube-system.svc.cluster.local"
            - "clustermesh-apiserver.kube-system"
            - "clustermesh-apiserver"

# k8s:
#   requireIPv4PodCIDR: true
#   requireIPv6PodCIDR: false
# tunnel: disabled
# ipv4NativeRoutingCIDR: ${ipv4_native_routing_cidr}

# endpointRoutes:
#   enabled: true

# cni:
#   binPath: /home/kubernetes/bin

# encryption:
#   enabled: false
#   type: wireguard
#   nodeEncryption: false

# l7Proxy: true
# autoDirectNodeRoutes: false
# enableIPv4Masquerade: true